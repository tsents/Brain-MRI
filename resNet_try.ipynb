{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "3182 657 90\n",
      "                            ID  \\\n",
      "812   TCGA_DU_7302_19911203_33   \n",
      "1550  TCGA_HT_7602_19951103_17   \n",
      "2228  TCGA_DU_A5TR_19970726_31   \n",
      "1108  TCGA_DU_5872_19950223_26   \n",
      "3728  TCGA_FG_7643_20021104_17   \n",
      "\n",
      "                                                  Image  \\\n",
      "812   kaggle_3m/TCGA_DU_7302_19911203/TCGA_DU_7302_1...   \n",
      "1550  kaggle_3m/TCGA_HT_7602_19951103/TCGA_HT_7602_1...   \n",
      "2228  kaggle_3m/TCGA_DU_A5TR_19970726/TCGA_DU_A5TR_1...   \n",
      "1108  kaggle_3m/TCGA_DU_5872_19950223/TCGA_DU_5872_1...   \n",
      "3728  kaggle_3m/TCGA_FG_7643_20021104/TCGA_FG_7643_2...   \n",
      "\n",
      "                                                   Mask  Diagnosis  \n",
      "812   kaggle_3m/TCGA_DU_7302_19911203/TCGA_DU_7302_1...          0  \n",
      "1550  kaggle_3m/TCGA_HT_7602_19951103/TCGA_HT_7602_1...          0  \n",
      "2228  kaggle_3m/TCGA_DU_A5TR_19970726/TCGA_DU_A5TR_1...          0  \n",
      "1108  kaggle_3m/TCGA_DU_5872_19950223/TCGA_DU_5872_1...          0  \n",
      "3728  kaggle_3m/TCGA_FG_7643_20021104/TCGA_FG_7643_2...          0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "PATH = \"kaggle_3m\"\n",
    "IMAGE_SIZE = (256, 256)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "paths = []\n",
    "\n",
    "for dirname in os.listdir(PATH):\n",
    "    if os.path.isdir(os.path.join(PATH, dirname)):\n",
    "        \n",
    "        for filename in os.listdir(os.path.join(PATH, dirname)):\n",
    "            if filename.endswith('.tif'):\n",
    "                paths.append(PATH+'/'+dirname+'/'+filename)\n",
    "\n",
    "\n",
    "def data_frame(data):\n",
    "    images = list(filter(lambda x: not x.endswith('mask.tif'), data))\n",
    "    images.sort(key=lambda x: int(x.rsplit('_', 3)[-1][:-4]))\n",
    "    images.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n",
    "    \n",
    "    IDs = list(map(lambda x: x.rsplit('/', 3)[-1][:-4], images))\n",
    "\n",
    "    masks = list(filter(lambda x: x.endswith('mask.tif'), data))\n",
    "    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n",
    "    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-3]))\n",
    "\n",
    "    pixels = lambda x: Image.open(x)\n",
    "    largest_pixel = lambda y: np.max(pixels(y))\n",
    "    diagnotic_function = lambda z: 1 if largest_pixel(z) > 0 else 0\n",
    "    diagnoses = list(map(lambda x: diagnotic_function(x), masks))\n",
    "\n",
    "    data_df = pd.DataFrame({'ID': IDs, 'Image': images, 'Mask': masks, 'Diagnosis': diagnoses})\n",
    "    \n",
    "    train_index, val_index = train_test_split(data_df.index.values.tolist(), test_size=0.19, random_state=42)\n",
    "    val_index, test_index = train_test_split(val_index, test_size=0.12, random_state=42)\n",
    "    \n",
    "    # Making train, test, and validation dataframes\n",
    "    train_df, val_df, test_df = data_df.iloc[train_index], data_df.iloc[val_index], data_df.iloc[test_index]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "    \n",
    "# Making the dataframes\n",
    "train_df, val_df, test_df = data_frame(paths)\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "def tensor_from_path(path):\n",
    "    arr = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    arr = cv2.resize(arr, IMAGE_SIZE)\n",
    "    arr = arr / 255\n",
    "    if len(arr.shape) == 3:\n",
    "        tensor = torch.tensor(arr).permute(2,0,1)\n",
    "    elif len(arr.shape) == 2:\n",
    "        tensor = torch.tensor(arr).unsqueeze(0)\n",
    "    else:\n",
    "        raise ValueError(f\"Expected data shape to be (..., ..., 3) or (..., ...) , but got {arr.shape}\")\n",
    "    return tensor\n",
    "\n",
    "class data(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df        \n",
    "        self.images = self.df.loc[:,'Image'].values\n",
    "        self.masks = self.df.loc[:,'Mask'].values\n",
    "        self.diagnosis = self.df.loc[:,'Diagnosis'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im_path = self.images[idx]\n",
    "        msk_path= self.masks[idx]\n",
    "        diagnosis = self.diagnosis[idx]\n",
    "        self.im_tensor = tensor_from_path(im_path)\n",
    "        self.msk_tensor= tensor_from_path(msk_path)\n",
    "        return self.im_tensor.to(device), self.msk_tensor.to(device),diagnosis\n",
    "\n",
    "train_ds = data(train_df)\n",
    "test_ds = data(test_df)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32)\n",
    "test_dl = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BottleNeckBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        base_width = 64\n",
    "        width = int(out_channels * (base_width / 64.)) * 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=width, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=width)\n",
    "        self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=width)\n",
    "        self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channels * self.expansion, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        print(f\"Input: {x.shape}\")\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        print(f\"After conv1: {out.shape}\")\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        print(f\"After conv2: {out.shape}\")\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        print(f\"After conv3: {out.shape}\")\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            print(f\"Downsampled identity: {identity.shape}\")\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        print(f\"Output: {out.shape}\")\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # resnet stem\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # res-blocks\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        # classifier block\n",
    "        self.adppool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(in_features=512 * block.expansion, out_features=num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channels, out_channels=out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_features=out_channels * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Input: {x.shape}\")\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        print(f\"After conv1: {x.shape}\")\n",
    "        x = self.maxpool(x)\n",
    "        print(f\"After maxpool: {x.shape}\")\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        print(f\"After layer1: {x.shape}\")\n",
    "        x = self.layer2(x)\n",
    "        print(f\"After layer2: {x.shape}\")\n",
    "        x = self.layer3(x)\n",
    "        print(f\"After layer3: {x.shape}\")\n",
    "        x = self.layer4(x)\n",
    "        print(f\"After layer4: {x.shape}\")\n",
    "\n",
    "        x = self.adppool(x)\n",
    "        print(f\"After adppool: {x.shape}\")\n",
    "        x = torch.flatten(x, 1)\n",
    "        print(f\"After flatten: {x.shape}\")\n",
    "\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResNet                                   --\n",
      "├─Conv2d: 1-1                            9,408\n",
      "├─BatchNorm2d: 1-2                       128\n",
      "├─ReLU: 1-3                              --\n",
      "├─MaxPool2d: 1-4                         --\n",
      "├─Sequential: 1-5                        --\n",
      "│    └─BottleNeckBlock: 2-1              --\n",
      "│    │    └─Conv2d: 3-1                  4,096\n",
      "│    │    └─BatchNorm2d: 3-2             128\n",
      "│    │    └─Conv2d: 3-3                  4,096\n",
      "│    │    └─BatchNorm2d: 3-4             128\n",
      "│    │    └─Conv2d: 3-5                  16,384\n",
      "│    │    └─BatchNorm2d: 3-6             512\n",
      "│    │    └─ReLU: 3-7                    --\n",
      "│    └─BottleNeckBlock: 2-2              --\n",
      "│    │    └─Conv2d: 3-8                  16,384\n",
      "│    │    └─BatchNorm2d: 3-9             128\n",
      "│    │    └─Conv2d: 3-10                 36,864\n",
      "│    │    └─BatchNorm2d: 3-11            128\n",
      "│    │    └─Conv2d: 3-12                 16,384\n",
      "│    │    └─BatchNorm2d: 3-13            512\n",
      "│    │    └─ReLU: 3-14                   --\n",
      "│    └─BottleNeckBlock: 2-3              --\n",
      "│    │    └─Conv2d: 3-15                 16,384\n",
      "│    │    └─BatchNorm2d: 3-16            128\n",
      "│    │    └─Conv2d: 3-17                 36,864\n",
      "│    │    └─BatchNorm2d: 3-18            128\n",
      "│    │    └─Conv2d: 3-19                 16,384\n",
      "│    │    └─BatchNorm2d: 3-20            512\n",
      "│    │    └─ReLU: 3-21                   --\n",
      "├─Sequential: 1-6                        --\n",
      "│    └─BottleNeckBlock: 2-4              --\n",
      "│    │    └─Conv2d: 3-22                 32,768\n",
      "│    │    └─BatchNorm2d: 3-23            256\n",
      "│    │    └─Conv2d: 3-24                 65,536\n",
      "│    │    └─BatchNorm2d: 3-25            256\n",
      "│    │    └─Conv2d: 3-26                 65,536\n",
      "│    │    └─BatchNorm2d: 3-27            1,024\n",
      "│    │    └─ReLU: 3-28                   --\n",
      "│    └─BottleNeckBlock: 2-5              --\n",
      "│    │    └─Conv2d: 3-29                 65,536\n",
      "│    │    └─BatchNorm2d: 3-30            256\n",
      "│    │    └─Conv2d: 3-31                 147,456\n",
      "│    │    └─BatchNorm2d: 3-32            256\n",
      "│    │    └─Conv2d: 3-33                 65,536\n",
      "│    │    └─BatchNorm2d: 3-34            1,024\n",
      "│    │    └─ReLU: 3-35                   --\n",
      "│    └─BottleNeckBlock: 2-6              --\n",
      "│    │    └─Conv2d: 3-36                 65,536\n",
      "│    │    └─BatchNorm2d: 3-37            256\n",
      "│    │    └─Conv2d: 3-38                 147,456\n",
      "│    │    └─BatchNorm2d: 3-39            256\n",
      "│    │    └─Conv2d: 3-40                 65,536\n",
      "│    │    └─BatchNorm2d: 3-41            1,024\n",
      "│    │    └─ReLU: 3-42                   --\n",
      "│    └─BottleNeckBlock: 2-7              --\n",
      "│    │    └─Conv2d: 3-43                 65,536\n",
      "│    │    └─BatchNorm2d: 3-44            256\n",
      "│    │    └─Conv2d: 3-45                 147,456\n",
      "│    │    └─BatchNorm2d: 3-46            256\n",
      "│    │    └─Conv2d: 3-47                 65,536\n",
      "│    │    └─BatchNorm2d: 3-48            1,024\n",
      "│    │    └─ReLU: 3-49                   --\n",
      "├─Sequential: 1-7                        --\n",
      "│    └─BottleNeckBlock: 2-8              --\n",
      "│    │    └─Conv2d: 3-50                 131,072\n",
      "│    │    └─BatchNorm2d: 3-51            512\n",
      "│    │    └─Conv2d: 3-52                 262,144\n",
      "│    │    └─BatchNorm2d: 3-53            512\n",
      "│    │    └─Conv2d: 3-54                 262,144\n",
      "│    │    └─BatchNorm2d: 3-55            2,048\n",
      "│    │    └─ReLU: 3-56                   --\n",
      "│    └─BottleNeckBlock: 2-9              --\n",
      "│    │    └─Conv2d: 3-57                 262,144\n",
      "│    │    └─BatchNorm2d: 3-58            512\n",
      "│    │    └─Conv2d: 3-59                 589,824\n",
      "│    │    └─BatchNorm2d: 3-60            512\n",
      "│    │    └─Conv2d: 3-61                 262,144\n",
      "│    │    └─BatchNorm2d: 3-62            2,048\n",
      "│    │    └─ReLU: 3-63                   --\n",
      "│    └─BottleNeckBlock: 2-10             --\n",
      "│    │    └─Conv2d: 3-64                 262,144\n",
      "│    │    └─BatchNorm2d: 3-65            512\n",
      "│    │    └─Conv2d: 3-66                 589,824\n",
      "│    │    └─BatchNorm2d: 3-67            512\n",
      "│    │    └─Conv2d: 3-68                 262,144\n",
      "│    │    └─BatchNorm2d: 3-69            2,048\n",
      "│    │    └─ReLU: 3-70                   --\n",
      "│    └─BottleNeckBlock: 2-11             --\n",
      "│    │    └─Conv2d: 3-71                 262,144\n",
      "│    │    └─BatchNorm2d: 3-72            512\n",
      "│    │    └─Conv2d: 3-73                 589,824\n",
      "│    │    └─BatchNorm2d: 3-74            512\n",
      "│    │    └─Conv2d: 3-75                 262,144\n",
      "│    │    └─BatchNorm2d: 3-76            2,048\n",
      "│    │    └─ReLU: 3-77                   --\n",
      "│    └─BottleNeckBlock: 2-12             --\n",
      "│    │    └─Conv2d: 3-78                 262,144\n",
      "│    │    └─BatchNorm2d: 3-79            512\n",
      "│    │    └─Conv2d: 3-80                 589,824\n",
      "│    │    └─BatchNorm2d: 3-81            512\n",
      "│    │    └─Conv2d: 3-82                 262,144\n",
      "│    │    └─BatchNorm2d: 3-83            2,048\n",
      "│    │    └─ReLU: 3-84                   --\n",
      "│    └─BottleNeckBlock: 2-13             --\n",
      "│    │    └─Conv2d: 3-85                 262,144\n",
      "│    │    └─BatchNorm2d: 3-86            512\n",
      "│    │    └─Conv2d: 3-87                 589,824\n",
      "│    │    └─BatchNorm2d: 3-88            512\n",
      "│    │    └─Conv2d: 3-89                 262,144\n",
      "│    │    └─BatchNorm2d: 3-90            2,048\n",
      "│    │    └─ReLU: 3-91                   --\n",
      "├─Sequential: 1-8                        --\n",
      "│    └─BottleNeckBlock: 2-14             --\n",
      "│    │    └─Conv2d: 3-92                 524,288\n",
      "│    │    └─BatchNorm2d: 3-93            1,024\n",
      "│    │    └─Conv2d: 3-94                 1,048,576\n",
      "│    │    └─BatchNorm2d: 3-95            1,024\n",
      "│    │    └─Conv2d: 3-96                 1,048,576\n",
      "│    │    └─BatchNorm2d: 3-97            4,096\n",
      "│    │    └─ReLU: 3-98                   --\n",
      "│    └─BottleNeckBlock: 2-15             --\n",
      "│    │    └─Conv2d: 3-99                 1,048,576\n",
      "│    │    └─BatchNorm2d: 3-100           1,024\n",
      "│    │    └─Conv2d: 3-101                2,359,296\n",
      "│    │    └─BatchNorm2d: 3-102           1,024\n",
      "│    │    └─Conv2d: 3-103                1,048,576\n",
      "│    │    └─BatchNorm2d: 3-104           4,096\n",
      "│    │    └─ReLU: 3-105                  --\n",
      "│    └─BottleNeckBlock: 2-16             --\n",
      "│    │    └─Conv2d: 3-106                1,048,576\n",
      "│    │    └─BatchNorm2d: 3-107           1,024\n",
      "│    │    └─Conv2d: 3-108                2,359,296\n",
      "│    │    └─BatchNorm2d: 3-109           1,024\n",
      "│    │    └─Conv2d: 3-110                1,048,576\n",
      "│    │    └─BatchNorm2d: 3-111           4,096\n",
      "│    │    └─ReLU: 3-112                  --\n",
      "├─AdaptiveAvgPool2d: 1-9                 --\n",
      "├─Linear: 1-10                           2,049\n",
      "=================================================================\n",
      "Total params: 18,980,417\n",
      "Trainable params: 18,980,417\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "resnet34 = ResNet(block=BottleNeckBlock, layers=[3,4,6,3], num_classes=1).to(device)\n",
    "from torchinfo import summary\n",
    "\n",
    "print(summary(resnet34, input_shape=(4, 3, 256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Current accaracy: 25 %\n",
      "Accuracy of the network on the train images: 25 %\n",
      "epoch 0\n",
      "Current accaracy: 61 %\n",
      "Accuracy of the network on the train images: 60 %\n",
      "epoch 0\n",
      "Current accaracy: 64 %\n",
      "Accuracy of the network on the train images: 62 %\n",
      "epoch 0\n",
      "Current accaracy: 63 %\n",
      "Accuracy of the network on the train images: 62 %\n",
      "epoch 0\n",
      "Current accaracy: 70 %\n",
      "Accuracy of the network on the train images: 64 %\n",
      "epoch 0\n",
      "Current accaracy: 63 %\n",
      "Accuracy of the network on the train images: 64 %\n",
      "epoch 0\n",
      "Current accaracy: 62 %\n",
      "Accuracy of the network on the train images: 64 %\n",
      "epoch 0\n",
      "Current accaracy: 62 %\n",
      "Accuracy of the network on the train images: 63 %\n",
      "epoch 1\n",
      "Current accaracy: 0 %\n",
      "Accuracy of the network on the train images: 0 %\n",
      "epoch 1\n",
      "Current accaracy: 68 %\n",
      "Accuracy of the network on the train images: 67 %\n",
      "epoch 1\n",
      "Current accaracy: 62 %\n",
      "Accuracy of the network on the train images: 64 %\n",
      "epoch 1\n",
      "Current accaracy: 70 %\n",
      "Accuracy of the network on the train images: 66 %\n",
      "epoch 1\n",
      "Current accaracy: 67 %\n",
      "Accuracy of the network on the train images: 66 %\n",
      "epoch 1\n",
      "Current accaracy: 72 %\n",
      "Accuracy of the network on the train images: 67 %\n",
      "epoch 1\n",
      "Current accaracy: 70 %\n",
      "Accuracy of the network on the train images: 68 %\n",
      "epoch 1\n",
      "Current accaracy: 69 %\n",
      "Accuracy of the network on the train images: 68 %\n",
      "epoch 2\n",
      "Current accaracy: 50 %\n",
      "Accuracy of the network on the train images: 50 %\n",
      "epoch 2\n",
      "Current accaracy: 73 %\n",
      "Accuracy of the network on the train images: 73 %\n",
      "epoch 2\n",
      "Current accaracy: 71 %\n",
      "Accuracy of the network on the train images: 72 %\n",
      "epoch 2\n",
      "Current accaracy: 75 %\n",
      "Accuracy of the network on the train images: 73 %\n",
      "epoch 2\n",
      "Current accaracy: 76 %\n",
      "Accuracy of the network on the train images: 74 %\n",
      "epoch 2\n",
      "Current accaracy: 72 %\n",
      "Accuracy of the network on the train images: 73 %\n",
      "epoch 2\n",
      "Current accaracy: 73 %\n",
      "Accuracy of the network on the train images: 73 %\n",
      "epoch 2\n",
      "Current accaracy: 73 %\n",
      "Accuracy of the network on the train images: 73 %\n",
      "epoch 3\n",
      "Current accaracy: 75 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 3\n",
      "Current accaracy: 74 %\n",
      "Accuracy of the network on the train images: 74 %\n",
      "epoch 3\n",
      "Current accaracy: 79 %\n",
      "Accuracy of the network on the train images: 76 %\n",
      "epoch 3\n",
      "Current accaracy: 71 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 3\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 3\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 3\n",
      "Current accaracy: 70 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 3\n",
      "Current accaracy: 74 %\n",
      "Accuracy of the network on the train images: 74 %\n",
      "epoch 4\n",
      "Current accaracy: 75 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 4\n",
      "Current accaracy: 74 %\n",
      "Accuracy of the network on the train images: 74 %\n",
      "epoch 4\n",
      "Current accaracy: 74 %\n",
      "Accuracy of the network on the train images: 74 %\n",
      "epoch 4\n",
      "Current accaracy: 76 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 4\n",
      "Current accaracy: 76 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 4\n",
      "Current accaracy: 76 %\n",
      "Accuracy of the network on the train images: 75 %\n",
      "epoch 4\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 76 %\n",
      "epoch 4\n",
      "Current accaracy: 78 %\n",
      "Accuracy of the network on the train images: 76 %\n",
      "epoch 5\n",
      "Current accaracy: 50 %\n",
      "Accuracy of the network on the train images: 50 %\n",
      "epoch 5\n",
      "Current accaracy: 80 %\n",
      "Accuracy of the network on the train images: 80 %\n",
      "epoch 5\n",
      "Current accaracy: 73 %\n",
      "Accuracy of the network on the train images: 76 %\n",
      "epoch 5\n",
      "Current accaracy: 76 %\n",
      "Accuracy of the network on the train images: 76 %\n",
      "epoch 5\n",
      "Current accaracy: 78 %\n",
      "Accuracy of the network on the train images: 77 %\n",
      "epoch 5\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 77 %\n",
      "epoch 5\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 77 %\n",
      "epoch 5\n",
      "Current accaracy: 80 %\n",
      "Accuracy of the network on the train images: 77 %\n",
      "epoch 6\n",
      "Current accaracy: 100 %\n",
      "Accuracy of the network on the train images: 100 %\n",
      "epoch 6\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 77 %\n",
      "epoch 6\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 77 %\n",
      "epoch 6\n",
      "Current accaracy: 78 %\n",
      "Accuracy of the network on the train images: 78 %\n",
      "epoch 6\n",
      "Current accaracy: 74 %\n",
      "Accuracy of the network on the train images: 77 %\n",
      "epoch 6\n",
      "Current accaracy: 75 %\n",
      "Accuracy of the network on the train images: 76 %\n",
      "epoch 6\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 76 %\n",
      "epoch 6\n",
      "Current accaracy: 77 %\n",
      "Accuracy of the network on the train images: 77 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "resnet34 = ResNet18()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(resnet34.parameters(), lr=0.001)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "for epoch in range(7):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    current_predicted = 0\n",
    "    current_total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        inputs, _,labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet34(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = torch.round(outputs.data) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        current_total += labels.size(0)\n",
    "        current_predicted += (predicted == labels).sum().item()\n",
    "        if i % 100 == 0:\n",
    "            print('epoch',epoch)\n",
    "            print('Current accaracy: %d %%' % (100 * current_predicted / current_total))\n",
    "            print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "            current_predicted = 0\n",
    "            current_total = 0\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "net = models.resnet18()\n",
    "print(net)\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net18 = models.resnet18()\n",
    "        self.fc = nn.Linear(1000,1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net18(x)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
