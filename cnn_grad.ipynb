{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "PATH = \"kaggle_3m\"\n",
    "IMAGE_SIZE = (256, 256)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "paths = []\n",
    "\n",
    "for dirname in os.listdir(PATH):\n",
    "    if os.path.isdir(os.path.join(PATH, dirname)):\n",
    "        \n",
    "        for filename in os.listdir(os.path.join(PATH, dirname)):\n",
    "            if filename.endswith('.tif'):\n",
    "                paths.append(PATH+'/'+dirname+'/'+filename)\n",
    "\n",
    "\n",
    "def data_frame(data):\n",
    "    images = list(filter(lambda x: not x.endswith('mask.tif'), data))\n",
    "    images.sort(key=lambda x: int(x.rsplit('_', 3)[-1][:-4]))\n",
    "    images.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n",
    "    \n",
    "    IDs = list(map(lambda x: x.rsplit('/', 3)[-1][:-4], images))\n",
    "\n",
    "    masks = list(filter(lambda x: x.endswith('mask.tif'), data))\n",
    "    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n",
    "    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-3]))\n",
    "\n",
    "    pixels = lambda x: Image.open(x)\n",
    "    largest_pixel = lambda y: np.max(pixels(y))\n",
    "    diagnotic_function = lambda z: 1 if largest_pixel(z) > 0 else 0\n",
    "    diagnoses = list(map(lambda x: diagnotic_function(x), masks))\n",
    "\n",
    "    data_df = pd.DataFrame({'ID': IDs, 'Image': images, 'Mask': masks, 'Diagnosis': diagnoses})\n",
    "    \n",
    "    train_index, val_index = train_test_split(data_df.index.values.tolist(), test_size=0.19, random_state=42)\n",
    "    val_index, test_index = train_test_split(val_index, test_size=0.12, random_state=42)\n",
    "    \n",
    "    # Making train, test, and validation dataframes\n",
    "    train_df, val_df, test_df = data_df.iloc[train_index], data_df.iloc[val_index], data_df.iloc[test_index]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "    \n",
    "# Making the dataframes\n",
    "train_df, val_df, test_df = data_frame(paths)\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "def tensor_from_path(path):\n",
    "    arr = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    arr = cv2.resize(arr, IMAGE_SIZE)\n",
    "    arr = arr / 255\n",
    "    if len(arr.shape) == 3:\n",
    "        tensor = torch.tensor(arr).permute(2,0,1)\n",
    "    elif len(arr.shape) == 2:\n",
    "        tensor = torch.tensor(arr).unsqueeze(0)\n",
    "    else:\n",
    "        raise ValueError(f\"Expected data shape to be (..., ..., 3) or (..., ...) , but got {arr.shape}\")\n",
    "    return tensor\n",
    "\n",
    "class data(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df        \n",
    "        self.images = self.df.loc[:,'Image'].values\n",
    "        self.masks = self.df.loc[:,'Mask'].values\n",
    "        self.diagnosis = self.df.loc[:,'Diagnosis'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im_path = self.images[idx]\n",
    "        msk_path= self.masks[idx]\n",
    "        diagnosis = self.diagnosis[idx]\n",
    "        self.im_tensor = tensor_from_path(im_path)\n",
    "        self.msk_tensor= tensor_from_path(msk_path)\n",
    "        return self.im_tensor.to(device), self.msk_tensor.to(device),diagnosis\n",
    "\n",
    "train_ds = data(train_df)\n",
    "test_ds = data(test_df)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32)\n",
    "test_dl = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 61 * 61, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        starts at torch.Size([4, 3, 256, 256])\n",
    "        torch.Size([4, 6, 252, 252])\n",
    "        torch.Size([4, 6, 126, 126])\n",
    "        torch.Size([4, 16, 122, 122])\n",
    "        torch.Size([4, 16, 61, 61])`\n",
    "        then flattens to NN\n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 16 * 61 * 61)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "for epoch in range(7):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    current_predicted = 0\n",
    "    current_total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        inputs, _,labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = torch.round(outputs.data) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        current_total += labels.size(0)\n",
    "        current_predicted += (predicted == labels).sum().item()\n",
    "        if i % 100 == 0:\n",
    "            print('epoch',epoch)\n",
    "            print('Current accaracy: %d %%' % (100 * current_predicted / current_total))\n",
    "            print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "            current_predicted = 0\n",
    "            current_total = 0\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "for data in test_dataloader:\n",
    "    images,_, labels = data\n",
    "    images = images.float().to(device)\n",
    "    labels = labels.float().to(device)\n",
    "    outputs = net(images).squeeze()\n",
    "    predicted = (outputs.data > 0.1)\n",
    "    print(labels,predicted)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    all_predicted.extend(predicted.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "accuracy = 100 * correct / total\n",
    "precision = precision_score(all_labels, all_predicted)\n",
    "recall = recall_score(all_labels, all_predicted)\n",
    "\n",
    "# Print the results\n",
    "print('Accuracy of the network on the test images: %d %%' % accuracy)\n",
    "print('Precision of the network on the test images: %f' % precision)\n",
    "print('Recall of the network on the test images: %f' % recall)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install grad-cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For grad cam explaination \n",
    "\n",
    "https://github.com/jacobgil/pytorch-grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import HiResCAM, EigenCAM,AblationCAM,XGradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def visualize_prediction(path):\n",
    "    target_layers = [net.conv2]\n",
    "    input_tensor = tensor_from_path(path).float().to(device)\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "    rgb_img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    rgb_img = cv2.resize(rgb_img, IMAGE_SIZE)\n",
    "    rgb_img = np.array(rgb_img,dtype=np.float32)\n",
    "    rgb_img /= 256\n",
    "\n",
    "    fig,ax=plt.subplots(nrows=2,ncols=2)\n",
    "\n",
    "    fig.suptitle(torch.round(net(input_tensor).squeeze()).cpu().detach().numpy())\n",
    "\n",
    "    ax[0][0].axis('off')   \n",
    "    ax[0][0].imshow(rgb_img)\n",
    "\n",
    "\n",
    "    mask_img = cv2.imread(path.replace('.tif','_mask.tif'), cv2.IMREAD_UNCHANGED)\n",
    "    mask_img = cv2.resize(mask_img, IMAGE_SIZE)\n",
    "\n",
    "    ax[1][0].axis('off')   \n",
    "    ax[1][0].imshow(mask_img,cmap='gray')\n",
    "\n",
    "    i = 2\n",
    "    methods = [XGradCAM,AblationCAM]\n",
    "\n",
    "    for method in methods:\n",
    "        start = time.time()\n",
    "        cam = method(model=net, target_layers=target_layers)\n",
    "        grayscale_cam = cam(input_tensor=input_tensor)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "\n",
    "        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True,image_weight=0)\n",
    "\n",
    "        ax[i%2][i//2].axis('off')\n",
    "        ax[i%2][i//2].imshow(visualization)\n",
    "        i+=1\n",
    "        plt.plot()\n",
    "\n",
    "visualize_prediction('kaggle_3m/TCGA_CS_5397_20010315/TCGA_CS_5397_20010315_8.tif')\n",
    "visualize_prediction('kaggle_3m/TCGA_CS_5397_20010315/TCGA_CS_5397_20010315_9.tif')\n",
    "visualize_prediction('kaggle_3m/TCGA_CS_5397_20010315/TCGA_CS_5397_20010315_10.tif')\n",
    "visualize_prediction('kaggle_3m/TCGA_CS_5397_20010315/TCGA_CS_5397_20010315_11.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a wierd fashion, even if the classification is wrong, we still get a good heatmap of abnormalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_prediction('kaggle_3m/TCGA_DU_A5TW_19980228/TCGA_DU_A5TW_19980228_11.tif')\n",
    "#this case is no cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,32):\n",
    "    visualize_prediction(f'kaggle_3m/TCGA_DU_A5TW_19980228/TCGA_DU_A5TW_19980228_{i}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,26):\n",
    "    visualize_prediction(f'kaggle_3m/TCGA_FG_6692_20020606/TCGA_FG_6692_20020606_{i}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,20):\n",
    "    visualize_prediction(f'kaggle_3m/TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_{i}.tif')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in test_df['Image']:\n",
    "    visualize_prediction(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is so cool and a good result too.\n",
    "One thing to note is that EigenCam method works the best for us, but it takes *100 longer to show, thus in cases when it might not be clear, we can use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another intresting note is that it looks that we fail mostly on the edge of the brain (top edge) where it looks blerry and small, with some cleaning of the data we might get better result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
