{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "PATH = \"kaggle_3m\"\n",
    "IMAGE_SIZE = (256, 256)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "paths = []\n",
    "\n",
    "for dirname in os.listdir(PATH):\n",
    "    if os.path.isdir(os.path.join(PATH, dirname)):\n",
    "        \n",
    "        for filename in os.listdir(os.path.join(PATH, dirname)):\n",
    "            if filename.endswith('.tif'):\n",
    "                paths.append(PATH+'/'+dirname+'/'+filename)\n",
    "\n",
    "\n",
    "def data_frame(data):\n",
    "    images = list(filter(lambda x: not x.endswith('mask.tif'), data))\n",
    "    images.sort(key=lambda x: int(x.rsplit('_', 3)[-1][:-4]))\n",
    "    images.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n",
    "    \n",
    "    IDs = list(map(lambda x: x.rsplit('/', 3)[-1][:-4], images))\n",
    "\n",
    "    masks = list(filter(lambda x: x.endswith('mask.tif'), data))\n",
    "    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n",
    "    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-3]))\n",
    "\n",
    "    pixels = lambda x: Image.open(x)\n",
    "    largest_pixel = lambda y: np.max(pixels(y))\n",
    "    diagnotic_function = lambda z: 1 if largest_pixel(z) > 0 else 0\n",
    "    diagnoses = list(map(lambda x: diagnotic_function(x), masks))\n",
    "\n",
    "    data_df = pd.DataFrame({'ID': IDs, 'Image': images, 'Mask': masks, 'Diagnosis': diagnoses})\n",
    "    \n",
    "    train_index, val_index = train_test_split(data_df.index.values.tolist(), test_size=0.19, random_state=42)\n",
    "    val_index, test_index = train_test_split(val_index, test_size=0.12, random_state=42)\n",
    "    \n",
    "    # Making train, test, and validation dataframes\n",
    "    train_df, val_df, test_df = data_df.iloc[train_index], data_df.iloc[val_index], data_df.iloc[test_index]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "    \n",
    "# Making the dataframes\n",
    "train_df, val_df, test_df = data_frame(paths)\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "def tensor_from_path(path):\n",
    "    arr = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    arr = cv2.resize(arr, IMAGE_SIZE)\n",
    "    arr = arr / 255\n",
    "    if len(arr.shape) == 3:\n",
    "        tensor = torch.tensor(arr).permute(2,0,1)\n",
    "    elif len(arr.shape) == 2:\n",
    "        tensor = torch.tensor(arr).unsqueeze(0)\n",
    "    else:\n",
    "        raise ValueError(f\"Expected data shape to be (..., ..., 3) or (..., ...) , but got {arr.shape}\")\n",
    "    return tensor\n",
    "\n",
    "class data(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df        \n",
    "        self.images = self.df.loc[:,'Image'].values\n",
    "        self.masks = self.df.loc[:,'Mask'].values\n",
    "        self.diagnosis = self.df.loc[:,'Diagnosis'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im_path = self.images[idx]\n",
    "        msk_path= self.masks[idx]\n",
    "        diagnosis = self.diagnosis[idx]\n",
    "        self.im_tensor = tensor_from_path(im_path)\n",
    "        self.msk_tensor= tensor_from_path(msk_path)\n",
    "        return self.im_tensor.to(device), self.msk_tensor.to(device),diagnosis\n",
    "\n",
    "train_ds = data(train_df)\n",
    "test_ds = data(test_df)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32)\n",
    "test_dl = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 61 * 61, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        starts at torch.Size([4, 3, 256, 256])\n",
    "        torch.Size([4, 6, 252, 252])\n",
    "        torch.Size([4, 6, 126, 126])\n",
    "        torch.Size([4, 16, 122, 122])\n",
    "        torch.Size([4, 16, 61, 61])`\n",
    "        then flattens to NN\n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 16 * 61 * 61)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    current_predicted = 0\n",
    "    current_total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        inputs, _,labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = torch.round(outputs.data) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        current_total += labels.size(0)\n",
    "        current_predicted += (predicted == labels).sum().item()\n",
    "        if i % 100 == 0:\n",
    "            print('Current accaracy: %d %%' % (100 * current_predicted / current_total))\n",
    "            print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "            current_predicted = 0\n",
    "            current_total = 0\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "with torch.no_grad():  # we don't need gradients for test, so it will save memory\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_dataloader:\n",
    "        images,_, labels = data\n",
    "        images = images.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        outputs = net(images).squeeze()\n",
    "        predicted = torch.round(outputs.data)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(correct,total,np.shape(predicted),np.shape(labels))\n",
    "        print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define the function to load and preprocess the image\n",
    "def get_img_array(img_path, size):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "# Function to generate the Grad-CAM heatmap\n",
    "def make_gradcam_heatmap(img_tensor, model, target_layer):\n",
    "    model.eval()\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    \n",
    "    # Forward pass to get predictions and features from the target layer\n",
    "    features = None\n",
    "    def hook_function(module, input, output):\n",
    "        nonlocal features\n",
    "        features = output\n",
    "    \n",
    "    handle = target_layer.register_forward_hook(hook_function)\n",
    "    \n",
    "    outputs = model(img_tensor)\n",
    "    handle.remove()\n",
    "    \n",
    "    # Get the index of the predicted class\n",
    "    pred_index = outputs.argmax(dim=1).item()\n",
    "    class_output = outputs[:, pred_index]\n",
    "    \n",
    "    # Backward pass to get gradients of the target layer\n",
    "    model.zero_grad()\n",
    "    class_output.backward(retain_graph=True)\n",
    "    \n",
    "    gradients = target_layer.weight.grad\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    \n",
    "    # Multiply each channel in the feature map by the corresponding gradient\n",
    "    for i in range(features.shape[1]):\n",
    "        features[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "    # Average the channels of the feature map\n",
    "    heatmap = features.mean(dim=1).squeeze()\n",
    "    \n",
    "    # Normalize the heatmap between 0 and 1\n",
    "    heatmap = np.maximum(heatmap.cpu().detach().numpy(), 0)\n",
    "    heatmap /= heatmap.max()\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "# Define the path to the image and the target layer\n",
    "img_path = \"kaggle_3m\\TCGA_CS_5397_20010315\\TCGA_CS_5397_20010315_10.tif\"\n",
    "target_layer = net.conv2\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_size = (256, 256)\n",
    "img_tensor = get_img_array(img_path, img_size)\n",
    "\n",
    "# Generate the Grad-CAM heatmap\n",
    "heatmap = make_gradcam_heatmap(img_tensor, net, target_layer)\n",
    "\n",
    "# Display the heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()\n",
    "\n",
    "# Superimpose the heatmap on the original image\n",
    "img = cv2.imread(img_path)\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "# Display the superimposed image\n",
    "cv2.imshow('Grad-CAM', superimposed_img / 255)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
